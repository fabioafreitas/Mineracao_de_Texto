{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "equiPy.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "e_FppKQ50iWS",
        "HwKOYXFfBiKl"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHJ3mAhUpvo6",
        "colab_type": "text"
      },
      "source": [
        "# Clonando Repositório"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDcFNDhInN8p",
        "colab_type": "code",
        "outputId": "c02b5b90-55a4-4836-ed72-ef11bd0ab9bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "!git clone https://github.com/ufrpe-mineracao-textos/projeto-de-mineracao-20192-equipy.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'projeto-de-mineracao-20192-equipy'...\n",
            "remote: Enumerating objects: 27, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 27 (delta 11), reused 18 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (27/27), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdU8Pvyj0PCj",
        "colab_type": "text"
      },
      "source": [
        "# Carregando Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMe2EvEnBqLV",
        "colab_type": "code",
        "outputId": "cf9db094-88db-43fb-e905-fc15492e3fce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        }
      },
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "from spacy.lang.pt.stop_words import STOP_WORDS\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "\n",
        "!python -m spacy download pt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pt_core_news_sm==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.1.0/pt_core_news_sm-2.1.0.tar.gz (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.9MB 1.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pt-core-news-sm\n",
            "  Building wheel for pt-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pt-core-news-sm: filename=pt_core_news_sm-2.1.0-cp36-none-any.whl size=12843677 sha256=f137148fef56ef3eeb02a3ba59ff6dfc5251309a4b490b1723c1876b9328b0db\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-iqwkui2e/wheels/a3/8f/c1/f036e3a7f1aa44fb06a534c6c4b1c2b773f101fdb1f163c08c\n",
            "Successfully built pt-core-news-sm\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/pt_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/pt\n",
            "You can now load the model via spacy.load('pt')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9odCcScpt8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('pt')\n",
        "\n",
        "path = \"projeto-de-mineracao-20192-equipy/\"\n",
        "data = pd.read_csv(path+\"new_dataset.csv\")\n",
        "\n",
        "docs = []\n",
        "docs_lemma = []\n",
        "\n",
        "for index, row in data.iterrows():\n",
        "  text = row['text'].lower()\n",
        "  text = nlp(text)\n",
        "  \n",
        "  text_x = \"\".join([token.text + \" \" for token in text if not (token.is_punct or token.is_stop)])\n",
        "  # Remove as pontuações e as stop words e faz o Lemmatization\n",
        "  text_lemma = \"\".join([token.lemma_ + \" \" for token in text if not (token.is_punct or token.is_stop)])\n",
        "\n",
        "  docs.append({ 'text': text_x, 'label': row['label'] }) \n",
        "  docs_lemma.append({ 'text': text_lemma }) \n",
        "\n",
        "docs = pd.DataFrame(docs)\n",
        "docs_lemma = pd.DataFrame(docs_lemma)\n",
        "\n",
        "texto, classe = docs['text'], docs['label']\n",
        "texto_lemma = docs_lemma['text']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cqnp6AKa1PQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "treino_texto = texto[:1300]\n",
        "teste_texto = texto[1301:2000]\n",
        "\n",
        "treino_classe = classe[:1300]\n",
        "teste_classe = classe[1301:2000]\n",
        "\n",
        "treino_lemma_texto = texto_lemma[:1300]\n",
        "teste_lemma_texto = texto_lemma[1301:2000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YAs1wjg1ja_",
        "colab_type": "text"
      },
      "source": [
        "# Extração de caracteristicas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqXAVX8y2vSx",
        "colab_type": "text"
      },
      "source": [
        "## Sem Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G1qw3Tx1nQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_vect = CountVectorizer(encoding='latin-1')\n",
        "\n",
        "X_treino_counts = count_vect.fit_transform(treino_texto)\n",
        "X_treino_counts.shape\n",
        "\n",
        "tfidf_transformer = TfidfTransformer(use_idf=True)\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_treino_counts)\n",
        "X_train_tfidf.shape\n",
        "\n",
        "X_teste_counts = count_vect.transform(teste_texto)\n",
        "X_teste_tfidf = tfidf_transformer.transform(X_teste_counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3XdCM4s3Hzy",
        "colab_type": "text"
      },
      "source": [
        "## Com Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVw7yQNf10ev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_vect_lemma = CountVectorizer(encoding='latin-1')\n",
        "\n",
        "X_treino_lemma_counts = count_vect_lemma.fit_transform(treino_lemma_texto)\n",
        "X_treino_lemma_counts.shape\n",
        "\n",
        "tfidf_transformer_lemma = TfidfTransformer(use_idf=True)\n",
        "X_train_lemma_tfidf = tfidf_transformer_lemma.fit_transform(X_treino_lemma_counts)\n",
        "X_train_lemma_tfidf.shape\n",
        "\n",
        "X_teste_lemma_counts = count_vect_lemma.transform(teste_lemma_texto)\n",
        "X_teste_lemma_tfidf = tfidf_transformer_lemma.transform(X_teste_lemma_counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDCA3g4s0Hgj",
        "colab_type": "text"
      },
      "source": [
        "# Classificação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_FppKQ50iWS",
        "colab_type": "text"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBt8b4-p5IWU",
        "colab_type": "text"
      },
      "source": [
        "### Sem Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6negBgm01_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classf_nb = MultinomialNB().fit(X_train_tfidf, treino_classe)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRxkHJRf2EAe",
        "colab_type": "text"
      },
      "source": [
        "#### Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ5OL-u52KXh",
        "colab_type": "code",
        "outputId": "a8b73134-5800-49da-a101-25f0b2c3c097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "predito_nb = classf_nb.predict(X_teste_tfidf)\n",
        "accuracy_score(teste_classe, predito_nb)\n",
        "\n",
        "print(metrics.classification_report(teste_classe, predito_nb))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.54      0.64       399\n",
            "           1       0.57      0.80      0.66       300\n",
            "\n",
            "    accuracy                           0.65       699\n",
            "   macro avg       0.68      0.67      0.65       699\n",
            "weighted avg       0.69      0.65      0.65       699\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7-uZApo0oxx",
        "colab_type": "text"
      },
      "source": [
        "### Com Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWQ5YIsA1mnt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classf_nb_lemma = MultinomialNB().fit(X_train_lemma_tfidf, treino_classe)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw0j5XWk31ie",
        "colab_type": "text"
      },
      "source": [
        "#### Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rAvZtIv35OM",
        "colab_type": "code",
        "outputId": "2ec197e3-7279-466f-b429-3e871b7c72bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "predito_nb_lemma = classf_nb_lemma.predict(X_teste_lemma_tfidf)\n",
        "accuracy_score(teste_classe, predito_nb_lemma)\n",
        "\n",
        "print(metrics.classification_report(teste_classe, predito_nb_lemma))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.56      0.65       399\n",
            "           1       0.58      0.79      0.67       300\n",
            "\n",
            "    accuracy                           0.66       699\n",
            "   macro avg       0.68      0.68      0.66       699\n",
            "weighted avg       0.69      0.66      0.66       699\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VY6Ju1Z0xU2",
        "colab_type": "text"
      },
      "source": [
        "## Árvore de Decisão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VXBibul6Ef4",
        "colab_type": "text"
      },
      "source": [
        "### Sem Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wPTQUsR6leV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classf_tree = DecisionTreeClassifier().fit(X_train_tfidf, treino_classe)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqtjDEUI6Mnk",
        "colab_type": "text"
      },
      "source": [
        "#### Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbDPfEFK6mX_",
        "colab_type": "code",
        "outputId": "5a5aa35d-4fd8-44bf-b05e-773db0aa16f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "predito_tree = classf_tree.predict(X_teste_tfidf)\n",
        "accuracy_score(teste_classe, predito_tree)\n",
        "\n",
        "print(metrics.classification_report(teste_classe, predito_tree))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.37      0.48       399\n",
            "           1       0.48      0.78      0.60       300\n",
            "\n",
            "    accuracy                           0.55       699\n",
            "   macro avg       0.59      0.58      0.54       699\n",
            "weighted avg       0.60      0.55      0.53       699\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWVMzmji6KAi",
        "colab_type": "text"
      },
      "source": [
        "### Com Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrVi3yzM6nIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classf_tree_lemma = DecisionTreeClassifier().fit(X_train_lemma_tfidf, treino_classe)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApqVx0PB6O34",
        "colab_type": "text"
      },
      "source": [
        "#### Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnJrACYl6n6Q",
        "colab_type": "code",
        "outputId": "a44e3346-f122-431d-983f-7ab1c618d385",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "predito_tree_lemma = classf_tree_lemma.predict(X_teste_lemma_tfidf)\n",
        "accuracy_score(teste_classe, predito_tree_lemma)\n",
        "\n",
        "print(metrics.classification_report(teste_classe, predito_tree_lemma))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.46       399\n",
            "           1       0.46      0.74      0.57       300\n",
            "\n",
            "    accuracy                           0.52       699\n",
            "   macro avg       0.56      0.55      0.52       699\n",
            "weighted avg       0.57      0.52      0.51       699\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwKOYXFfBiKl",
        "colab_type": "text"
      },
      "source": [
        "## Redes Neurais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqb0C1KEBlGP",
        "colab_type": "text"
      },
      "source": [
        "### Sem Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFSfW1CuBze6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classf_mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1).fit(X_train_tfidf, treino_classe)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IJM09qvBxJT",
        "colab_type": "text"
      },
      "source": [
        "#### Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_uJ-xQFBovx",
        "colab_type": "code",
        "outputId": "fb841388-42b3-4e39-e978-c3ee284c3ea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "predito_mlp = classf_mlp.predict(X_teste_tfidf)\n",
        "accuracy_score(teste_classe, predito_mlp)\n",
        "\n",
        "print(metrics.classification_report(teste_classe, predito_mlp))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.76      0.71       399\n",
            "           1       0.61      0.49      0.54       300\n",
            "\n",
            "    accuracy                           0.65       699\n",
            "   macro avg       0.64      0.63      0.63       699\n",
            "weighted avg       0.64      0.65      0.64       699\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deYab2ZQBpXz",
        "colab_type": "text"
      },
      "source": [
        "### Com Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2MtxDxTBs16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classf_mlp_lemma = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1).fit(X_train_lemma_tfidf, treino_classe)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOxa0kvDB0-S",
        "colab_type": "text"
      },
      "source": [
        "#### Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdEib1EeB36O",
        "colab_type": "code",
        "outputId": "05b4205a-a251-41e4-ffc8-f7499814df6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "predito_mlp_lemma = classf_mlp_lemma.predict(X_teste_lemma_tfidf)\n",
        "accuracy_score(teste_classe, predito_mlp_lemma)\n",
        "\n",
        "print(metrics.classification_report(teste_classe, predito_mlp_lemma))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.98      0.72       399\n",
            "           1       0.58      0.04      0.07       300\n",
            "\n",
            "    accuracy                           0.58       699\n",
            "   macro avg       0.58      0.51      0.40       699\n",
            "weighted avg       0.58      0.58      0.44       699\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdZYJEriZnru",
        "colab_type": "text"
      },
      "source": [
        "## Random Forests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PL-LfQzQZv40",
        "colab_type": "text"
      },
      "source": [
        "### Sem Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czHZx8rLaTfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classf_rf = RandomForestClassifier(n_estimators=100).fit(X_train_tfidf, treino_classe)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D30wYAYsZ0E4",
        "colab_type": "text"
      },
      "source": [
        "#### Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoG5D1_Kagh8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "9f506b6a-ab6e-4515-9cb1-4e2eac1b3b4b"
      },
      "source": [
        "predito_rf = classf_rf.predict(X_teste_tfidf)\n",
        "accuracy_score(teste_classe, predito_rf)\n",
        "\n",
        "print(metrics.classification_report(teste_classe, predito_rf))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.30      0.43       399\n",
            "           1       0.49      0.89      0.63       300\n",
            "\n",
            "    accuracy                           0.55       699\n",
            "   macro avg       0.64      0.59      0.53       699\n",
            "weighted avg       0.66      0.55      0.52       699\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAj-_FHQZ2hC",
        "colab_type": "text"
      },
      "source": [
        "### Com Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzRXfY9zbWKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classf_rf_lemma = RandomForestClassifier(n_estimators=100).fit(X_train_lemma_tfidf, treino_classe)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qchuOZ0Z4X3",
        "colab_type": "text"
      },
      "source": [
        "#### Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JBkYGiIbeZw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "f393ca45-2edc-4093-d3a2-a3f71c3a83a6"
      },
      "source": [
        "predito_rf_lemma = classf_rf_lemma.predict(X_teste_lemma_tfidf)\n",
        "accuracy_score(teste_classe, predito_rf_lemma)\n",
        "\n",
        "print(metrics.classification_report(teste_classe, predito_rf_lemma))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.26      0.39       399\n",
            "           1       0.48      0.90      0.62       300\n",
            "\n",
            "    accuracy                           0.53       699\n",
            "   macro avg       0.63      0.58      0.51       699\n",
            "weighted avg       0.65      0.53      0.49       699\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
